该论文提出了一种名为 **FedAVE (Federated learning framework with Adaptive data Value Evaluation mechanism)** 的新型联邦学习框架，旨在解决现有方法在评估客户端数据质量时忽略数据分布信息的问题，从而导致在不同数据异构性设置下奖励分配与客户端真实数据质量不匹配的问题，进而影响协作公平性。

现有联邦学习方法在分配全局模型时，通常不考虑客户端的贡献，这会抑制高质量客户端的积极参与。现有的协作公平性方法，例如基于相似度的方法 (CGSV) 和基于数据大小/标签多样性的方法 (CFFL)，在数据异构性（即数据大小和分布同时不同）变化时，未能有效地增强协作公平性。具体而言，在贡献评估阶段，现有方法无法公平评估不同客户端的声誉，例如 CGSV 可能高估与大多数客户端梯度相似的客户端，而 CFFL 仅依赖本地数据大小或标签多样性，无法同时准确评估所有客户端的真实声誉。在奖励分配阶段，如何确定分配梯度参数的哪些部分是一个挑战，因为即使梯度量微小差异也可能导致客户端模型性能相似，从而造成不公平待遇。

为解决这些问题，FedAVE 框架包含两个核心模块：**自适应声誉计算 (Adaptive Reputation Calculation, ARC) 模块** 和 **动态梯度奖励分配 (Dynamic Gradient Reward Distribution, DGR) 模块**。FedAVE 的目标是在不影响模型预测性能的前提下，确保协作公平性。

**核心方法学：**

1.  **FedAVE 概述：**
    FedAVE 的工作流程包括客户端采样、全局聚合、客户端声誉计算和奖励分配。在每轮通信中：
    *   **客户端采样：** 由于场景中客户端数量较少，本框架采用全采样，确保所有客户端都参与联邦学习。
    *   **全局聚合：** 服务器收集客户端上传的梯度，并进行加权平均聚合以生成新的全局模型梯度。客户端上传的梯度 $\Delta w^{(t)}_i$ 会首先进行归一化处理，即 $\Delta(w^S_i) = \Delta w^{(t)}_i \ast \tau / \Vert \Delta w^{(t)}_i \Vert$，其中 $\tau$ 为归一化系数，以防止梯度爆炸，并促进系统发展。全局聚合的梯度 $\Delta w^t_g$ 由以下公式计算：
        $$ \Delta w^t_g = \sum_{i=1}^m \frac{n_i}{\sum_{j=1}^m n_j} \ast \Delta(w^S_i) $$
        其中 $n_i$ 是客户端 $i$ 的数据量。
    *   **客户端声誉计算：** 服务器根据客户端数据分布信息和模型性能计算声誉。
    *   **奖励分配：** 服务器根据计算出的声誉向客户端分发聚合模型梯度参数作为奖励。

2.  **自适应声誉计算 (ARC) 模块：**
    该模块旨在更有效地利用数据分布信息来计算客户端声誉，以适应不同的数据异构性设置。受 FedKD 启发，FedAVE 通过客户端本地模型在服务器验证集上的性能以及本地数据集与验证集之间的 Kullback–Leibler (KL) 散度来计算声誉。验证集被假定为标准数据（与所有本地数据的并集具有相同的数据分布）。如果客户端本地数据集上的损失分布与验证集上的损失分布越接近，则表明其数据质量与验证集越相似，从而被视为高贡献客户端。客户端 $i$ 在第 $t$ 轮的临时声誉 $\tilde{r}^{(t)}_i$ 和平滑声誉 $r^{(t)}_i$ 通过以下公式计算：
    $$ \tilde{r}^{(t)}_i = Acc^{(t)}_i / KL(Loss^{(t)}_i, Loss^{(t)}_{V_i}) $$
    $$ r^{(t)}_i = \alpha \ast r^{(t-1)}_i + (1 - \alpha) \ast \tilde{r}^{(t)}_i $$
    其中，$Acc^{(t)}_i$ 是客户端 $i$ 的模型在验证集上的性能；$Loss^{(t)}_i$ 和 $Loss^{(t)}_{V_i}$ 分别表示模型 $i$ 在客户端 $i$ 本地数据集和验证集上测试时损失值的分布；$\alpha$ 是一个自适应权重，用于平滑声誉计算，消除训练过程中的噪声。最后，声誉 $r^{(t)}_i$ 会进行归一化处理：$r^{(t)}_i = r^{(t)}_i / \sum_{j=1}^m r^{(t)}_j$。

3.  **动态梯度奖励分配 (DGR) 模块：**
    该模块根据客户端的贡献分配相应的聚合模型参数梯度作为奖励，以确保奖励（即模型性能）具有显著区别。与现有简单地根据声誉分配奖励的方法不同，DGR 模块为客户端 $i$ 分配的梯度参数数量 $quota^t_i$ 和奖励梯度 $\Delta w^{*(t)}_i$ 计算如下：
    $$ quota^t_i := D \times \tanh(\beta r^{(t)}_i) / (\max_{j \in N} \tanh(\beta r^{(t)}_j) \ast KL(Loss^{(t)}_i, Loss^{(t)}_{V_i})) $$
    $$ \Delta w^{*(t)}_i = \text{sparsify}(\Delta w^{(t)}_g, quota^t_i) $$
    其中 $D$ 是模型参数向量的维度；$\beta$ 是一个超参数；$\text{sparsify}(\cdot, \cdot)$ 函数表示根据 $quota^t_i$ 的大小，从全局梯度 $\Delta w^{(t)}_g$ 中保留权重幅值最大的 $max(0, quota^t_i)$ 个分量，其余分量置零。这种基于权重幅值的参数剪裁和分配策略不仅有助于奖励分配，还能避免模型发散，因为模型权重幅值与其重要性之间存在强相关性。

**实验结果与讨论：**

论文在 MNIST、CIFAR-10 和 EMNIST letters 三个公共基准数据集上进行了广泛实验。为了模拟数据异构性，构建了三种数据划分场景：POW (数据大小不平衡)、CLA (类别数量不平衡) 和 DIR (数据大小和类别数量均不平衡，使用 Dirichlet 分布)。
实验结果表明，FedAVE 在公平性方面显著优于所有基线方法 (FedAvg, CFFL, CGSV)。公平性通过客户端独立模型测试准确率（代表贡献）和协作后本地模型测试准确率（代表奖励）之间的 Pearson 相关系数 $\gamma$ 进行量化。$\gamma$ 值越高，表示框架的公平性越好。FedAVE 在大多数异构设置下都实现了超过 84% 的高公平性，远高于 FedAvg（最低为 6.52%）。在预测性能方面，FedAVE 的最高准确率与 FedAvg 相当，并始终优于独立训练 (Standalone) 的模型。消融研究证明，ARC 模块和 DGR 模块都是 FedAVE 框架中提升协作公平性不可或缺的重要组成部分。
